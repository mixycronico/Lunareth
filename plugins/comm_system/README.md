# ğŸŒ± CommSystem

**Tu asistente conversacional vivo para CoreC**  
Chat real, memoria persistente y generaciÃ³n de plugins onâ€‘demand.

---

## âœ¨ CaracterÃ­sticas

- **Chat dinÃ¡mico** con `google/gemini-2.0-flash-lite-001` vÃ­a OpenRouter  
- **Memoria inteligente** (hasta 50 intercambios) almacenada en Redis y respaldo en disco  
- **Comandos por Redis Streams** (sincronÃ­a total, sin HTTP/WebSocket)  
- **Scaffolding onâ€‘demand**: crea nuevos plugins con un solo comando  
- **Modo mantenimiento**: consulta estado, lista mÃ³dulos/plugins y mÃ¡s  

---

## ğŸš€ InstalaciÃ³n

1. **Copia** el plugin en tu Ã¡rbol de CoreC:
   ```bash
   cp -R comm_system plugins/comm_system

  2.	Instala dependencias:

pip install -r plugins/comm_system/requirements.txt


  3.	Configura tu APIâ€‘Key de OpenRouter:

export OPENROUTER_API_KEY="tu_api_key"


  4.	Reinicia CoreC:

bash run.sh



â¸»

âš™ï¸ ConfiguraciÃ³n

Edita plugins/comm_system/config.json:

{
  "comm_system": {
    "stream_in":           "corec_commands",
    "stream_out":          "corec_responses",
    "openrouter_api_key":  "${OPENROUTER_API_KEY}",
    "openrouter_api_base": "https://openrouter.ai/api/v1",
    "openrouter_model":    "google/gemini-2.0-flash-lite-001",
    "max_tokens":          200,
    "temperature":         0.7,
    "memory_ttl":          3600,
    "memory_file":         "plugins/comm_system/memory.json"
  }
}

  â€¢	stream_in / stream_out: nombres de Redis Streams.
  â€¢	openrouter_*: credenciales y modelo.
  â€¢	memory_ttl: duraciÃ³n de la memoria en segundos.
  â€¢	memory_file: ruta de respaldo JSON.

â¸»

ğŸ“š Uso

EnvÃ­a JSON al stream de entrada y recibe la respuesta por el stream de salida.

Ejemplo en Python

import asyncio, json
from aioredis import from_url

async def enviar_comando(cmd):
    r = await from_url("redis://:password@localhost:6379", decode_responses=True)
    await r.xadd("corec_commands", {"data": json.dumps(cmd)})
    # Espera y lee la respuesta
    resp = await r.xread({"corec_responses": "0-0"}, count=1, block=5000)
    print("Respuesta:", json.loads(resp[0][1][0][1]["data"]))

# Chat
asyncio.run(enviar_comando({
    "action": "chat",
    "params": {"mensaje": "Â¿CÃ³mo va el sistema?"}
}))

# Estado de CoreC
asyncio.run(enviar_comando({ "action": "status" }))



â¸»

ğŸ› ï¸ Desarrollo
  â€¢	CÃ³digo fuente en plugins/comm_system/
  â€¢	Processors:
  â€¢	memory.py â†’ gestiÃ³n de historial
  â€¢	ai_chat.py â†’ llamadas a OpenRouter
  â€¢	manager.py â†’ loop de comandos
  â€¢	Utils: helpers.py para I/O asÃ­ncrono
  â€¢	Tests: crea tus casos en tests/test_comm_system.py

â¸»

ğŸ¤ Contribuir
  1.	Haz un fork del repositorio.
  2.	Crea tu rama de feature: git checkout -b feature/nombre
  3.	AsegÃºrate de pasar lint y tests:

black . && flake8 && pytest -q


  4.	EnvÃ­a un pull request describiendo tus cambios.

â¸»

ğŸ“„ Licencia

MIT Â© 2025 Moises Alvarenga & Luna

â¸»
